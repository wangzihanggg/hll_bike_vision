# 2022 智能车视觉部分程序

## 1、Unet车道线检测部分
- 数据集
使用的是 `labelme` 标注的数据集，标注结过为位深度为 8 的标注图，但是在训练的时候，在进行读取的时候使用的 `PIL.Image` API 进行读取原图像，并将其转化为 `RGB` 格式的进行训练，但是这样就要求模型的输入为 `B-C-W-H` 结构，会增加模型的参数量，导致模型较大，同时在读取标注图像的时候也是将 `P ` 格式的 8 位深度图转化为了 24 位的深度图，这样也会增加最终模型的输出为 `3-W-H` ，也会增加模型的大小。
- 模型的修改
在训练的时候使用的是 `BCE-Loss` ，即二分类交叉熵损失，我们只有两类，使用二分类损失是可以的，但是该损失要求数据输入只能是一个在  $0-1$ 之间的概率值，因此在最终的模型输出之前我们要加上 `torch.nn.Sigmoid()` 层进行归一化处理。
- 训练
训练时会将每轮的一个训练过程进行一个可视化，使用的是 `tochvision.utils.saveimage()` ,可以直观的看到训练过程中的特征图的变化。注意在前几轮的训练过程中注意特征图的变化过程，如果出现黑屏则说明模型架构出错。
- 问题
注意我在使用 `Sigmoid` 函数的时候刚开始并没有将其放在模型中去，而是直接在训练时，在放入损失函数之前将其套入，这样是不行的，因为实际上这也是一个参数训练的过程。
- 数据增强
其中并没有使用数据增强，只是使用 `transform.ToTesnsor()` 将其归一化而已，后面建议数据增强均使用 `Pytorch` 提供的数据增强功能，例如水平翻转，随机裁剪等。保持比例的 `resize` 可以保留。

### 1.1 net
- **UNet**
这个是原作者的开源框架，并没有做更改，参数大小约为 125MB
- **UNetBig**
加入 `Sigmoid() `之后的框架，使用` in_channel=3`,`out_channel=3` 时，参数大熊啊约为 28MB
- **UNetSmall**
未测试

### 1.2 待实现部分(可选)

- tensort 加速
- c++ 重鲁
- libtorch
- opencv+dnn
